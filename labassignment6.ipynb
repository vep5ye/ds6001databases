{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 6: Creating and Connecting to Databases\n",
    "## DS 6001: Practice and Application of Data Science\n",
    "\n",
    "### Instructions\n",
    "Please answer the following questions as completely as possible using text, code, and the results of code as needed. Format your answers in a Jupyter notebook. To receive full credit, make sure you address every part of the problem, and make sure your document is formatted in a clean and professional way.\n",
    "\n",
    "**Please note: you will not be able to use Rivanna for this lab as Rivanna is not set up to work with Docker or with Databases. If you need help getting your local system running, please let me know.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 0 [No points, no need to write anything here for any of the following parts, but do it anyway!]\n",
    "Databases require a lot of external software. The good news is that there are excellent free and open source options to do very advanced work with databases. The bad news is that each piece of additional software comes with its own complications. This problem will guide you through the installation steps for the software you need to run database systems on your computer, document those databases, and connect to them through Python with (fingers crossed) as few problems as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Use `pip` to install the following Python packages on your system:\n",
    "```\n",
    "mysql-connector-python\n",
    "psycopg\n",
    "pymongo\n",
    "sqlalchemy\n",
    "wget\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "With the exception of SQlite, database systems run as external software that must be installed and run on your computer. To make the installation steps easier, you will need some configuration files that I wrote and saved in a GitHub repository. Open your terminal and use the `cd` command to navigate to the folder in your computer where you want to work. Then type\n",
    "```\n",
    "git clone https://github.com/jkropko/ds6001databases\n",
    "```\n",
    "If this command works, it will create a new directory within your current folder called \"ds6001databases\".\n",
    "\n",
    "* Check that this folder exists and contains the following files: LICENSE, README.md, compose.yaml, db_tests.ipynb, and requirements.txt\n",
    "* Save the notebook file you will be using for your Lab 6 work inside the \"ds6001databases\" folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "We will be using a system called Docker to work with databases. Docker is the most commonly used platform for working with **containers**. While we will not be delving into the topic of containerization in this course, a container is space in your computer's memory that is set apart from the rest of your computer. We can act as if the container is an entirely new computer, and inside the container we can change the operating system and install other software external to Python, such as database management systems. We can use a container to run Windows on a Mac, or vice versa, or Linux on any system. By far the easiest way to run MySQL, PostgreSQL, and MongoDB is through Docker containers. \n",
    "\n",
    "You will need to install Docker Desktop on your computer. Go to https://www.docker.com/products/docker-desktop/ and click on the Download button, making sure the operating system listed matches the operating system of your computer.\n",
    "\n",
    "Once Docker Desktop is installed, find the Docker Desktop program on your computer and run it.\n",
    "\n",
    "To confirm that Docker Desktop is running, open a terminal and type `docker help`. If you see documentation that begins\n",
    "```\n",
    "Usage:  docker [OPTIONS] COMMAND\n",
    "\n",
    "A self-sufficient runtime for containers\n",
    "```\n",
    "then you are all set. If you see an error that Docker is not found, then the Docker Desktop client was not installed properly, so you should try downloading and installing it from the website again. If you receive a message that the Docker daemon is not running, then Docker is installed but is not running. Find the Docker Desktop executable on your computer and click it to get Docker running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part d\n",
    "Inside your \"ds6001databases\" folder, create a .env file. On a Mac, type `touch .env` then `open .env` to create and open the file. On Windows, open a new file on Notepad and go to \"Save As\", then save it in your \"ds6001databases\" folder -- make sure to set \"File As Type\" to \"All files\" and name the file \".env\".\n",
    "\n",
    "Inside the .env file you need to choose passwords for the MySQL, PostgreSQL, and MongoDB databases, so type\n",
    "```\n",
    "MYSQL_ROOT_PASSWORD=redlobstercheddarbiscuits\n",
    "POSTGRES_PASSWORD=outbackbloominonion\n",
    "MONGO_INITDB_ROOT_PASSWORD=olivegardenunlimitedbreadsticks\n",
    "MONGO_INITDB_ROOT_USERNAME=mongo\n",
    "mongo_init_db = mongodb\n",
    "MYSQL_DATABASE=mysql\n",
    "```\n",
    "Change the passwords on the first three lines to whatever you want, but DON'T USE THE @ SYMBOL as that will cause problems. Leave the fourth, fifth, and sixth lines alone, as well as the names of each environmental variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part e\n",
    "In the terminal, make sure you are in the \"ds6001databases\" folder (you can check by typing `pwd`. If not, then use `cd` to navigate to the \"ds6001databases\" folder). Then type\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "This command launches all of the databases. If successful, you will see a long stream of output with messages that begin `ds6001databases-postgres-1`, `ds6001databases-mysql-1`, and `ds6001databases-mongo-1`. If not, we will need to debug together, but the issue likely has to do with something preventing parts a, b, c, or d from being completed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part f\n",
    "To confirm that the databases are running on your system, open the \"db_tests.ipynb\" notebook file, which should be saved in you \"ds6001databases\" folder. Run everything in this notebook and make sure there are no errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part g\n",
    "In addition to the databases, we will be using dbdocs.io to create documentation for our databases and post them online with a stable URL. But to get dbdocs running, you first need to install NodeJS on your computer: https://nodejs.org/en\n",
    "\n",
    "Then to install dbdocs, follow the instructions here: https://dbdocs.io/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part h\n",
    "Finally, create a notebook inside your \"ds6001databases\" folder for your work on this lab. Import the following libraries, and load the `.env` file where you store your passwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wget\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import mysql.connector\n",
    "import psycopg\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "MONGO_INITDB_ROOT_USERNAME = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "MONGO_INITDB_ROOT_PASSWORD = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "mongo_init_db = os.getenv('mongo_init_db')\n",
    "MYSQL_ROOT_PASSWORD = os.getenv('MYSQL_ROOT_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 \n",
    "**This problem requires you to create Markdown tables** \n",
    "\n",
    "To create a table in a markdown cell, I recommend using the markdown table generator here: https://www.tablesgenerator.com/markdown_tables. This interface allows you to choose the number of rows and columns, fill in those rows and colums, and push the \"generate\" button. The website will display markdown table code that looks like:\n",
    "```\n",
    "| Day       | Temp | Rain |\n",
    "|-----------|------|------|\n",
    "| Monday    | 74   | No   |\n",
    "| Tuesday   | 58   | Yes  |\n",
    "| Wednesday | 76   | No   |\n",
    "```\n",
    "Copy the markdown code and paste it into a markdown cell in your notebook. Markdown will read the code and display a table that looks like this:\n",
    "\n",
    "| Day       | Temp | Rain |\n",
    "|-----------|------|------|\n",
    "| Monday    | 74   | No   |\n",
    "| Tuesday   | 58   | Yes  |\n",
    "| Wednesday | 76   | No   |\n",
    "\n",
    "Suppose that we have (fake) data on people who were hospitalized and received at least one prescription for a medication. Here are ten records in the data:\n",
    "\n",
    "(If this table gets cut off in the PDF, please look at the .ipynb notebook file on the module 6 page on Canvas)\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug | prior_conditions                     | patient_sex | patient_insurance      | drug_maker               | drug_cost | attending_physician | AP_medschool                      | AP_years_experience | hospital                       | hospital_location |\n",
    "|--------------------|---------------|-----------------|--------------------------------------|-------------|------------------------|--------------------------|-----------|---------------------|-----------------------------------|--------------------|--------------------------------|-------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          | [Pneumonia, Diabetes]                | M           | Aetna                  | USAntibiotics            | 14.62     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       | [Pneumonia, Diabetes]                | M           | Aetna                  | Pfizer                   | 20.55     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           | [Appendicitis, Crohn's disease]      | M           | Cigna                  | Baxter International Inc | 394.00    | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          | [Appendicitis, Crohn's disease]      | M           | Cigna                  | Abbvie                   | 7000.00   | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          | [Kidney Cancer]                      | F           | Kaiser Permanente      | Pfizer                   | 21644.00  | Lewis Conti         | North Carolina State University   | 8                  | Houston Methodist Hospital     | Houston, TX       |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Mylan Pharmaceuticals    | 10.58     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Pfizer                   | 20.55     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Pfizer                   | 37.50     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          | [Pancreatic Cancer, Sciatica]        | F           | Blue Cross Blue Shield | Genentech                | 860.00    | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         | [Pancreatic Cancer, Sciatica]        | F           | Blue Cross Blue Shield | Pfizer                   | 37.50     | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "\n",
    "The columns in this dataset are:\n",
    "\n",
    "* **patient_name**: The patient's name\n",
    "* **date_of_birth**: The patient's date of birth\n",
    "* **prescribed_drug**: The brand name of the medication that patient has been prescribed\n",
    "* **prior_conditions**: A list of the conditions that the patient had been diagnosed with prior to the patient's hospitalization\n",
    "* **patient_sex**: The patient's sex\n",
    "* **patient_insurance**: The company responsible for the patient's health insurance coverage\n",
    "* **drug_maker**: The company that manufactures the prescribed drug\n",
    "* **drug_cost**: The cost of the prescribed drug\n",
    "* **attending_physician**: The name of the attending physician for the patient\n",
    "* **AP_medschool**: The name of the school where the attending physician got a medical degree\n",
    "* **AP_years_experience**: The attending physician's number of years of experience post-residency\n",
    "* **hospital**: The hospital where the attending physicial is employed\n",
    "* **hospital_location**: The location of the hospital\n",
    "\n",
    "For this problem, assume that \n",
    "\n",
    "1. No two rows in this table share both the same patient and the same prescribed drug.\n",
    "   \n",
    "2. Some patients in the data share the same name, but no two patients in the data share the same name and date of birth.\n",
    "\n",
    "3. No two different drugs share the same brand name.\n",
    "\n",
    "4. No two attending physicians have the same name, and every attending physician is employed at only one hospital.\n",
    "\n",
    "5. No two hospitals share the same name, and every hospital exists at only one location.\n",
    "   \n",
    "6. Each patient has only one attending physician. (In real-world applications we may want to design a database that allows for multiple hospitalizations for some patients, but here we'll keep it simpler by assuming each patient has one hospitalization with one attending physician.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a \n",
    "Rearrange the data into a group of data tables that together meet the requirements of first normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b \n",
    "Rearrange the data on the five patients into a group of data tables that together meet the requirements of second normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c \n",
    "Rearrange the data into a group of data tables that together meet the requirements of third normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "For this problem, create ER diagrams of the database you created in problem 1, part c using https://dbdocs.io/. Make sure you install DBDocs on your system by following these instructions: https://dbdocs.io/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a \n",
    "Write code using the [database markup language](https://dbml.dbdiagram.io/home/) (DBML) that represents all of the tables in this database and the connections between the tables. Paste your DBML code in a markdown cell in your notebook, contained within three backticks to begin and end the code snippet, as shown in the cell below. \n",
    "\n",
    "Two good resources to help you:\n",
    "\n",
    "1. The example on the Getting Started page on dbdocs.io: https://dbdocs.io/docs\n",
    "2. The full syntax guide for DBML: https://dbml.dbdiagram.io/docs/#project-definition\n",
    "\n",
    "A few notes:\n",
    "* Make sure to specify the data type for each column in each table. Use varchar for strings/text, int for integers, and float for numeric data with decimals.\n",
    "* You will probably find it useful to alias each table with one or two letters, such as: Table PRESCRIPTIONS as PR. That will allow you to use PR to refer to the PRESCRIPTIONS table, for example, in the Reference statements to link tables together.\n",
    "* Use the syntax [pk] after a column name and data type to designate the columns that are primary keys in each table.\n",
    "* To draw the lines linking one table to another, use the Ref: syntax.\n",
    "    * If many rows from the left table match to one row in the right table, use the \"many to one\" symbol >\n",
    "    * If one row from the left table matches to many rows in the right table, use the \"one to many\" symbol <\n",
    "    * If one row from the left table matches to one row in the right table, use the \"one to one\" symbol -\n",
    "    * If many rows from the left table match to many rows in the right table, use the \"many to many\" symbol <>\n",
    "      \n",
    "[2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Make sure you get the .ipynb file for this lab from the module 6 page on Canvas\n",
    "\n",
    "Then when you double-click this box, you'll see three backticks before and after this text. Leave those alone\n",
    " \n",
    "Type your code here, between the backticks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Use the instructions on DBDocs.io (https://dbdocs.io/docs) to create a website for your ER diagram. Type the URL for your website in a markdown cell here. [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My example is here: https://dbdocs.io/jkropko/Lab6?view=relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "For this problem, you will download the individual CSV files that comprise a relational database on album reviews from [Pitchfork Magazine](https://pitchfork.com/), collected via webscraping by [Nolan B. Conaway](https://github.com/nolanbconaway/pitchfork-data), and use them to initialize local databases using SQlite, MySQL, and PostgreSQL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code of code will download the CSV files. Please run this as is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 83585024 / 83585024"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/nolanbconaway/pitchfork-data/raw/master/pitchfork.db\"\n",
    "pfork = wget.download(url)\n",
    "pitchfork = sqlite3.connect(pfork)\n",
    "for t in ['artists','content','genres','labels','reviews','years']:\n",
    "    datatable = pd.read_sql_query(\"SELECT * FROM {tab}\".format(tab=t), pitchfork)\n",
    "    datatable.to_csv(\"{tab}.csv\".format(tab=t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this code downloaded a SQlite database and extracted the tables, saving each one as a CSV. That seems backwards, as the purpose of this exercise is to create databases. But the point here is to practice creating databases from individual data frames. Next we load the CSVs to create the data frames in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv\")\n",
    "artists = pd.read_csv(\"artists.csv\")\n",
    "content = pd.read_csv(\"content.csv\")\n",
    "genres = pd.read_csv(\"genres.csv\")\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "years = pd.read_csv(\"years.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Initialize a new database using SQlite and the `sqlite3` library. Add the six dataframes to this database. Then issue the following query to the database\n",
    "```\n",
    "SELECT title, artist, score FROM reviews WHERE score=10\n",
    "```\n",
    "using two methods: first, using the `.cursor()` method, and second using `pd.read_sql_query()`. Finally, commit your changes to the database and close the database. (If you get a warning about spaces in the column names, feel free to ignore it this time.) [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "Follow the instructions in the Jupyter notebook for this module to install MySQL and `mysql.connector` on your computer. Make sure the MySQL server is running. Then import `mysql.connector` and do all of the tasks listed for part a using a MySQL database (including commiting changes and closing the database connection). Take steps to hide your password - do not let it display in your notebook. [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "Follow the instructions in the Jupyter notebook for this module to install PostgreSQL and `psycopg2` on your computer. Then import `psycopg2` and do all of the tasks listed for part a using a PostgreSQL database (including commiting changes and closing the database connection). Take steps to hide your password - do not let it display in your notebook. [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "[Colin Mitchell](http://muffinlabs.com/) is a web-developer and artist who has a bunch of [cool projects](http://muffinlabs.com/projects.html) that play with what data can do on the internet. One of his projects is [Today in History](https://history.muffinlabs.com/), which provides an API to access all the Wikipedia pages for historical events that happened on this day in JSON format. The records in this JSON are stored in the `['data']['events']` path. Here's the first listing for today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': '1249',\n",
       " 'text': 'Andrew of Longjumeau is dispatched by Louis IX of France as his ambassador to meet with the Khagan of the Mongol Empire.',\n",
       " 'html': '1249 - <a href=\"https://wikipedia.org/wiki/Andr%C3%A9_de_Longjumeau\" title=\"André de Longjumeau\">Andrew of Longjumeau</a> is dispatched by <a href=\"https://wikipedia.org/wiki/Louis_IX_of_France\" title=\"Louis IX of France\">Louis IX of France</a> as his <a href=\"https://wikipedia.org/wiki/Ambassador\" title=\"Ambassador\">ambassador</a> to meet with the <a href=\"https://wikipedia.org/wiki/Khagan\" title=\"Khagan\">Khagan</a> of the <a href=\"https://wikipedia.org/wiki/Mongol_Empire\" title=\"Mongol Empire\">Mongol Empire</a>.',\n",
       " 'no_year_html': '<a href=\"https://wikipedia.org/wiki/Andr%C3%A9_de_Longjumeau\" title=\"André de Longjumeau\">Andrew of Longjumeau</a> is dispatched by <a href=\"https://wikipedia.org/wiki/Louis_IX_of_France\" title=\"Louis IX of France\">Louis IX of France</a> as his <a href=\"https://wikipedia.org/wiki/Ambassador\" title=\"Ambassador\">ambassador</a> to meet with the <a href=\"https://wikipedia.org/wiki/Khagan\" title=\"Khagan\">Khagan</a> of the <a href=\"https://wikipedia.org/wiki/Mongol_Empire\" title=\"Mongol Empire\">Mongol Empire</a>.',\n",
       " 'links': [{'title': 'André de Longjumeau',\n",
       "   'link': 'https://wikipedia.org/wiki/Andr%C3%A9_de_Longjumeau'},\n",
       "  {'title': 'Louis IX of France',\n",
       "   'link': 'https://wikipedia.org/wiki/Louis_IX_of_France'},\n",
       "  {'title': 'Ambassador', 'link': 'https://wikipedia.org/wiki/Ambassador'},\n",
       "  {'title': 'Khagan', 'link': 'https://wikipedia.org/wiki/Khagan'},\n",
       "  {'title': 'Mongol Empire',\n",
       "   'link': 'https://wikipedia.org/wiki/Mongol_Empire'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = requests.get(\"https://history.muffinlabs.com/date\")\n",
    "history_json = json.loads(history.text)\n",
    "events = history_json['data']['Events']\n",
    "events[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, you will use MongoDB and the `pymongo` library to create a local document store NoSQL database containing these historical events.\n",
    "\n",
    "Follow the instructions in the Jupyter notebook for this module to install MongoDB and `pymongo` on your computer. Make sure the local MongoDB server is running. Then import `pymongo`, connect to the local MongoDB client, create a database named \"history\" and a collection within that database named \"today\". Insert all of the records in `events` into this collection. Then issue the following query to find all of the records whose text contain the word \"Virginia\":\n",
    "```\n",
    "query = {\n",
    "    \"text\":{\n",
    "        \"$regex\": 'Virginia'\n",
    "    }\n",
    "}\n",
    "```\n",
    "If there are no results that contain the word \"Virginia\", choose a different work like \"England\" or \"China\". Display the count of the number of documents that match this query, display the output of the query, and generate a JSON formatted variable containing the output. [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 [No points, no need to write anything here, but do it anyway!]\n",
    "When you are done working, go to the same terminal window you used to launch the databases with `docker compose up`. Here, type CONTROL + C on your keyboard to shut down the container.\n",
    "\n",
    "Next type\n",
    "```\n",
    "docker compose down\n",
    "```\n",
    "This step removes extra database software, networks, volumes, etc. running on your computer. If you don't need them, don't clog your computer.\n",
    "\n",
    "Whenever you need to work with databases, return to the terminal, navigate to this folder and type\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "to bring all these resources back online. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
